#!/usr/bin/env python3
"""
Argo Workflows API å®¢æˆ·ç«¯
ä½¿ç”¨ requests æäº¤å’Œç®¡ç†å·¥ä½œæµ

ç”¨æ³•ç¤ºä¾‹:
python3 argo_api_client.py --model_input /models/deepseek-v2 --task_input '["mmlu", "hellaswag"]'
python3 argo_api_client.py --model_input /models/deepseek-v2 --task_input mmlu,hellaswag --job_name my-test
python3 argo_api_client.py --list  # åˆ—å‡ºæ‰€æœ‰å·¥ä½œæµ
python3 argo_api_client.py --status workflow-name  # æŸ¥çœ‹å·¥ä½œæµçŠ¶æ€
"""

import requests
import json
import time
import urllib3
import argparse
import sys
import os
from pathlib import Path
from rich.console import Console
from rich.table import Table, box
from rich.text import Text
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from datetime import datetime

# å¿½ç•¥SSLè¯ä¹¦è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class ArgoWorkflowsClient:
    def __init__(self, server_url=None):
        # è‡ªåŠ¨æ£€æµ‹è¿è¡Œç¯å¢ƒ
        if server_url is None:
            # æ£€æŸ¥æ˜¯å¦åœ¨ Kubernetes Pod å†…éƒ¨
            if os.path.exists('/var/run/secrets/kubernetes.io/serviceaccount'):
                # Pod å†…éƒ¨ï¼Œä½¿ç”¨å†…éƒ¨æœåŠ¡å
                self.server_url = "https://argo-server.argo.svc.cluster.local:2746"
                print("ğŸ” æ£€æµ‹åˆ°è¿è¡Œåœ¨ Kubernetes Pod å†…ï¼Œä½¿ç”¨å†…éƒ¨æœåŠ¡åœ°å€")
            else:
                # Pod å¤–éƒ¨ï¼Œä½¿ç”¨å¤–éƒ¨ LoadBalancer IP
                self.server_url = "https://10.218.61.160"
                print("ğŸ” æ£€æµ‹åˆ°è¿è¡Œåœ¨ Pod å¤–éƒ¨ï¼Œä½¿ç”¨ LoadBalancer åœ°å€")
        else:
            self.server_url = server_url
            
        self.namespace = "argo"
        print(f"ğŸŒ Argo Server URL: {self.server_url}")
        
    def submit_workflow(self, job_name, model_input, task_input):
        """æäº¤å¤šæ¨¡å‹åµŒå¥—å·¥ä½œæµ"""
        url = f"{self.server_url}/api/v1/workflows/{self.namespace}"
        
        # ä¸ºæ¨¡å‹æ·»åŠ ç´¢å¼•ä¿¡æ¯
        model_list_with_index = []
        for i, model_path in enumerate(model_input):
            model_list_with_index.append({
                "path": model_path,
                "index": i
            })
        
        payload = {
            "workflow": {
                "metadata": {
                    "generateName": "multi-eval-api-",
                    "namespace": self.namespace
                },
                "spec": {
                    "workflowTemplateRef": {
                        "name": "deepseek-multi-model-eval-template"
                    },
                    "arguments": {
                        "parameters": [
                            {"name": "job_name", "value": job_name},
                            {"name": "project_name", "value": "deepseek_v2_lite"},
                            {"name": "model_list", "value": json.dumps(model_list_with_index)},
                            {"name": "task_list", "value": json.dumps(task_input)}
                        ]
                    }
                }
            }
        }
        
        response = requests.post(url, json=payload, verify=False)
        
        if response.status_code == 200:
            workflow_info = response.json()
            workflow_name = workflow_info['metadata']['name']
            print(f"âœ… åµŒå¥—å·¥ä½œæµæäº¤æˆåŠŸ: {workflow_name}")
            print(f"   ğŸ­ æ¨¡å‹æµæ°´çº¿: {len(model_input)} ä¸ª")
            print(f"   ğŸ“Š æ¯ä¸ªæ¨¡å‹çš„ä»»åŠ¡: {len(task_input)} ä¸ª")
            print(f"   ğŸ¯ æ€»è¯„ä¼°ä»»åŠ¡: {len(model_input) * len(task_input)} ä¸ª")
            return workflow_name
        else:
            print(f"âŒ æäº¤å¤±è´¥: {response.status_code} - {response.text}")
            return None
    
    def get_workflow_status(self, workflow_name):
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        url = f"{self.server_url}/api/v1/workflows/{self.namespace}/{workflow_name}"
        
        response = requests.get(url, verify=False)
        
        if response.status_code == 200:
            workflow = response.json()
            status = workflow['status']['phase']
            print(f"å·¥ä½œæµ {workflow_name} çŠ¶æ€: {status}")
            return workflow
        else:
            print(f"è·å–çŠ¶æ€å¤±è´¥: {response.status_code}")
            return None
    
    def list_workflows(self):
        """åˆ—å‡ºæ‰€æœ‰å·¥ä½œæµ"""
        url = f"{self.server_url}/api/v1/workflows/{self.namespace}"
        
        try:
            response = requests.get(url, verify=False, timeout=30)
            
            print(f"ğŸ” è¯·æ±‚ URL: {url}")
            print(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                try:
                    workflows = response.json()
                    if workflows is None:
                        print("âŒ API è¿”å›äº†ç©ºå“åº”")
                        return None
                        
                    items = workflows.get('items', [])
                    if not items:
                        print("ğŸ“ æš‚æ— å·¥ä½œæµ")
                        return workflows
                        
                    print("å·¥ä½œæµåˆ—è¡¨:")
                    for wf in items:
                        name = wf['metadata']['name']
                        status = wf['status']['phase']
                        created = wf['metadata'].get('creationTimestamp', 'N/A')
                        print(f"  {name}: {status} (åˆ›å»ºæ—¶é—´: {created})")
                    return workflows
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON è§£æå¤±è´¥: {e}")
                    print(f"ğŸ” å“åº”å†…å®¹: {response.text[:500]}...")
                    return None
            else:
                print(f"âŒ è·å–åˆ—è¡¨å¤±è´¥: {response.status_code}")
                print(f"ğŸ” é”™è¯¯å†…å®¹: {response.text}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
            print(f"ğŸ” è¯·æ£€æŸ¥ Argo Server æ˜¯å¦å¯è®¿é—®: {self.server_url}")
            return None
        except Exception as e:
            print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
            return None
    
    def get_workflow_logs(self, workflow_name):
        """è·å–å·¥ä½œæµæ—¥å¿—"""
        url = f"{self.server_url}/api/v1/workflows/{self.namespace}/{workflow_name}/log"
        
        response = requests.get(url, verify=False)
        
        if response.status_code == 200:
            print(f"å·¥ä½œæµ {workflow_name} æ—¥å¿—:")
            print(response.text)
            return response.text
        else:
            print(f"è·å–æ—¥å¿—å¤±è´¥: {response.status_code}")
            return None
    
    def get_workflow_tasks(self, workflow_name):
        """è·å–å·¥ä½œæµä¸­æ¯ä¸ªä»»åŠ¡çš„è¯¦ç»†çŠ¶æ€"""
        url = f"{self.server_url}/api/v1/workflows/{self.namespace}/{workflow_name}"
        
        try:
            response = requests.get(url, verify=False, timeout=30)
            
            if response.status_code == 200:
                workflow = response.json()
                
                print(f"ğŸ“Š å·¥ä½œæµ {workflow_name} ä»»åŠ¡è¯¦æƒ…:")
                print("=" * 60)
                
                # è·å–æ€»ä½“çŠ¶æ€
                overall_status = workflow['status']['phase']
                start_time = workflow['metadata'].get('creationTimestamp', 'N/A')
                print(f"ğŸ¯ æ€»ä½“çŠ¶æ€: {overall_status}")
                print(f"â° å¼€å§‹æ—¶é—´: {start_time}")
                print()
                
                # è·å–æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä»»åŠ¡ï¼‰çŠ¶æ€
                nodes = workflow['status'].get('nodes', {})
                
                if not nodes:
                    print("âŒ æœªæ‰¾åˆ°ä»»åŠ¡èŠ‚ç‚¹ä¿¡æ¯")
                    return None
                
                # æŒ‰ç…§ä»»åŠ¡ç±»å‹åˆ†ç»„æ˜¾ç¤º
                convert_tasks = []
                eval_tasks = []
                other_tasks = []
                
                for node_id, node in nodes.items():
                    node_name = node.get('displayName', node.get('name', 'unknown'))
                    phase = node.get('phase', 'Unknown')
                    start_time = node.get('startedAt', 'N/A')
                    finish_time = node.get('finishedAt', 'N/A')
                    
                    task_info = {
                        'name': node_name,
                        'phase': phase,
                        'start': start_time,
                        'finish': finish_time,
                        'node_id': node_id
                    }
                    
                    # è¯†åˆ«åµŒå¥—å·¥ä½œæµçš„ä»»åŠ¡ç±»å‹
                    if ('convert' in node_name.lower() or 
                        node_name.startswith('convert-models') or
                        'convert-model' in node_name.lower()):
                        # è½¬æ¢ä»»åŠ¡ï¼ˆæ”¯æŒå•æ¨¡å‹ã€å¤šæ¨¡å‹å’ŒåµŒå¥—å·¥ä½œæµï¼‰
                        convert_tasks.append(task_info)
                    elif ('run-eval' in node_name.lower() or 
                          'eval-tasks' in node_name.lower() or
                          node_name.startswith('eval-combinations') or
                          'run-single-eval' in node_name.lower()):
                        # è¯„ä¼°ä»»åŠ¡ï¼ˆæ”¾å®½æ¡ä»¶ï¼Œæ”¯æŒåµŒå¥—å·¥ä½œæµï¼‰
                        eval_tasks.append(task_info)
                    else:
                        other_tasks.append(task_info)
                
                # æ˜¾ç¤ºè½¬æ¢ä»»åŠ¡
                if convert_tasks:
                    print("ğŸ”„ æ¨¡å‹è½¬æ¢ä»»åŠ¡:")
                    for task in convert_tasks:
                        status_icon = self._get_status_icon(task['phase'])
                        print(f"  {status_icon} {task['name']}: {task['phase']}")
                        if task['start'] != 'N/A':
                            print(f"     å¼€å§‹: {task['start']}")
                        if task['finish'] != 'N/A':
                            print(f"     ç»“æŸ: {task['finish']}")
                        print()
                
                # æ˜¾ç¤ºè¯„ä¼°ä»»åŠ¡
                if eval_tasks:
                    print("ğŸ“Š è¯„ä¼°ä»»åŠ¡:")
                    for task in eval_tasks:
                        status_icon = self._get_status_icon(task['phase'])
                        print(f"  {status_icon} {task['name']}: {task['phase']}")
                        if task['start'] != 'N/A':
                            print(f"     å¼€å§‹: {task['start']}")
                        if task['finish'] != 'N/A':
                            print(f"     ç»“æŸ: {task['finish']}")
                        print()
                
                # æ˜¾ç¤ºå…¶ä»–ä»»åŠ¡
                if other_tasks:
                    print("ğŸ”§ å…¶ä»–ä»»åŠ¡:")
                    for task in other_tasks:
                        status_icon = self._get_status_icon(task['phase'])
                        print(f"  {status_icon} {task['name']}: {task['phase']}")
                        if task['start'] != 'N/A':
                            print(f"     å¼€å§‹: {task['start']}")
                        if task['finish'] != 'N/A':
                            print(f"     ç»“æŸ: {task['finish']}")
                        print()
                
                return workflow
            else:
                print(f"âŒ è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ è·å–ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return None
    
    def get_task_logs(self, workflow_name, task_name):
        """è·å–ç‰¹å®šä»»åŠ¡çš„æ—¥å¿—"""
        url = f"{self.server_url}/api/v1/workflows/{self.namespace}/{workflow_name}/{task_name}/log"
        
        try:
            response = requests.get(url, verify=False, timeout=30)
            
            if response.status_code == 200:
                print(f"ğŸ“‹ ä»»åŠ¡ {task_name} æ—¥å¿—:")
                print("-" * 40)
                print(response.text)
                return response.text
            else:
                print(f"âŒ è·å–ä»»åŠ¡ {task_name} æ—¥å¿—å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ è·å–ä»»åŠ¡æ—¥å¿—æ—¶å‡ºé”™: {e}")
            return None
    
    def get_workflow_tasks_detailed(self, workflow_name, show_logs=False):
        """è·å–å·¥ä½œæµä¸­æ¯ä¸ªä»»åŠ¡çš„è¯¦ç»†çŠ¶æ€ï¼Œæ”¯æŒæ˜¾ç¤ºæ—¥å¿—"""
        url = f"{self.server_url}/api/v1/workflows/{self.namespace}/{workflow_name}"
        
        try:
            response = requests.get(url, verify=False, timeout=30)
            
            if response.status_code == 200:
                workflow = response.json()
                
                print(f"ğŸ“Š å·¥ä½œæµ {workflow_name} è¯¦ç»†ä»»åŠ¡çŠ¶æ€:")
                print("=" * 80)
                
                # è·å–æ€»ä½“çŠ¶æ€
                overall_status = workflow['status']['phase']
                start_time = workflow['metadata'].get('creationTimestamp', 'N/A')
                print(f"ğŸ¯ æ€»ä½“çŠ¶æ€: {overall_status}")
                print(f"â° å¼€å§‹æ—¶é—´: {start_time}")
                print()
                
                # è·å–æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä»»åŠ¡ï¼‰çŠ¶æ€
                nodes = workflow['status'].get('nodes', {})
                
                if not nodes:
                    print("âŒ æœªæ‰¾åˆ°ä»»åŠ¡èŠ‚ç‚¹ä¿¡æ¯")
                    return None
                
                # æŒ‰ç…§æ‰§è¡Œé¡ºåºæ’åºå¹¶åˆ†ç±»æ˜¾ç¤º
                convert_tasks = []
                eval_tasks = []
                other_tasks = []
                
                for node_id, node in nodes.items():
                    node_name = node.get('displayName', node.get('name', 'unknown'))
                    phase = node.get('phase', 'Unknown')
                    start_time = node.get('startedAt', 'N/A')
                    finish_time = node.get('finishedAt', 'N/A')
                    pod_name = node.get('id', node_id)  # å®é™…çš„ pod åç§°
                    
                    task_info = {
                        'name': node_name,
                        'phase': phase,
                        'start': start_time,
                        'finish': finish_time,
                        'node_id': node_id,
                        'pod_name': pod_name
                    }
                    
                    # åªä¿ç•™æœ‰æ„ä¹‰çš„ä»»åŠ¡
                    if 'convert' in node_name.lower() or node_name.startswith('convert-models'):
                        # è½¬æ¢ä»»åŠ¡ï¼ˆæ”¯æŒå•æ¨¡å‹å’Œå¤šæ¨¡å‹å·¥ä½œæµï¼‰
                        convert_tasks.append(task_info)
                    elif ('run-eval' in node_name.lower() or 
                          'eval-tasks' in node_name.lower() or
                          node_name.startswith('eval-combinations') or
                          'run-single-eval' in node_name.lower()):
                        # è¯„ä¼°ä»»åŠ¡ï¼ˆæ”¾å®½æ¡ä»¶ï¼Œæ”¯æŒåµŒå¥—å·¥ä½œæµï¼‰
                        eval_tasks.append(task_info)
                    else:
                        other_tasks.append(task_info)
                
                # æ˜¾ç¤ºè½¬æ¢ä»»åŠ¡
                if convert_tasks:
                    print("ğŸ”„ æ¨¡å‹è½¬æ¢ä»»åŠ¡:")
                    for task in convert_tasks:
                        self._display_task_details(task, workflow_name, show_logs)
                
                # æ˜¾ç¤ºè¯„ä¼°ä»»åŠ¡
                if eval_tasks:
                    print("ğŸ“Š è¯„ä¼°ä»»åŠ¡:")
                    for i, task in enumerate(eval_tasks):
                        print(f"  ğŸ“‹ å­ä»»åŠ¡ {i+1}:")
                        self._display_task_details(task, workflow_name, show_logs, indent="    ")
                
                # æ˜¾ç¤ºå…¶ä»–ä»»åŠ¡
                if other_tasks:
                    print("ğŸ”§ å…¶ä»–ä»»åŠ¡:")
                    for task in other_tasks:
                        self._display_task_details(task, workflow_name, show_logs)
                
                return workflow
            else:
                print(f"âŒ è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ è·å–ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return None
    
    def _display_task_details(self, task, workflow_name, show_logs=False, indent="  "):
        """æ˜¾ç¤ºå•ä¸ªä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯"""
        status_icon = self._get_status_icon(task['phase'])
        print(f"{indent}{status_icon} {task['name']}: {task['phase']}")
        print(f"{indent}   Pod: {task['pod_name']}")
        
        if task['start'] != 'N/A':
            print(f"{indent}   å¼€å§‹: {task['start']}")
        if task['finish'] != 'N/A':
            print(f"{indent}   ç»“æŸ: {task['finish']}")
        
        # å¦‚æœè¦æ˜¾ç¤ºæ—¥å¿—ä¸”ä»»åŠ¡æ­£åœ¨è¿è¡Œæˆ–å·²å®Œæˆ
        if show_logs and task['phase'] in ['Running', 'Succeeded', 'Failed']:
            print(f"{indent}   ğŸ“‹ ä»»åŠ¡æ—¥å¿—:")
            print(f"{indent}   " + "-" * 40)
            try:
                logs = self.get_task_logs(workflow_name, task['pod_name'])
                if logs:
                    # åªæ˜¾ç¤ºæœ€åå‡ è¡Œæ—¥å¿—ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
                    log_lines = logs.strip().split('\n')
                    if len(log_lines) > 10:
                        print(f"{indent}   ... (çœç•¥å‰é¢çš„æ—¥å¿—)")
                        for line in log_lines[-10:]:
                            print(f"{indent}   {line}")
                    else:
                        for line in log_lines:
                            print(f"{indent}   {line}")
                    print(f"{indent}   " + "-" * 40)
            except Exception as e:
                print(f"{indent}   âŒ è·å–æ—¥å¿—å¤±è´¥: {e}")
        
        print()
    
    def _get_status_icon(self, phase):
        """æ ¹æ®ä»»åŠ¡çŠ¶æ€è¿”å›å¯¹åº”çš„å›¾æ ‡"""
        status_icons = {
            'Pending': 'â³',
            'Running': 'ğŸ”„',
            'Succeeded': 'âœ…',
            'Failed': 'âŒ',
            'Error': 'ğŸ’¥',
            'Skipped': 'â­ï¸',
            'Omitted': 'âšª'
        }
        return status_icons.get(phase, 'â“')
    
    def display_workflow_tasks_table(self, workflow_name):
        """ä½¿ç”¨ Rich è¡¨æ ¼æ˜¾ç¤ºå·¥ä½œæµä»»åŠ¡çŠ¶æ€"""
        url = f"{self.server_url}/api/v1/workflows/{self.namespace}/{workflow_name}"
        
        try:
            response = requests.get(url, verify=False, timeout=30)
            
            if response.status_code == 200:
                workflow = response.json()
                
                # åˆ›å»º Rich æ§åˆ¶å°
                console = Console(width=150)
                
                # è·å–æ€»ä½“çŠ¶æ€ä¿¡æ¯
                overall_status = workflow['status']['phase']
                start_time = workflow['metadata'].get('creationTimestamp', 'N/A')
                
                # æ˜¾ç¤ºå·¥ä½œæµåŸºæœ¬ä¿¡æ¯
                workflow_info = Table(title=f"ğŸš€ Workflow: {workflow_name}", box=box.ROUNDED)
                workflow_info.add_column("å±æ€§", style="cyan", width=20)
                workflow_info.add_column("å€¼", style="green")
                
                workflow_info.add_row("æ€»ä½“çŠ¶æ€", self._get_status_text(overall_status))
                workflow_info.add_row("å¼€å§‹æ—¶é—´", start_time)
                
                # è®¡ç®—è¿è¡Œæ—¶é•¿
                if start_time != 'N/A':
                    try:
                        start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
                        now = datetime.now(start_dt.tzinfo)
                        duration = str(now - start_dt).split('.')[0]  # å»æ‰å¾®ç§’
                        workflow_info.add_row("è¿è¡Œæ—¶é•¿", duration)
                    except:
                        workflow_info.add_row("è¿è¡Œæ—¶é•¿", "è®¡ç®—å¤±è´¥")
                
                console.print(workflow_info)
                console.print()
                
                # è·å–æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä»»åŠ¡ï¼‰çŠ¶æ€
                nodes = workflow['status'].get('nodes', {})
                
                if not nodes:
                    console.print("[red]âŒ æœªæ‰¾åˆ°ä»»åŠ¡èŠ‚ç‚¹ä¿¡æ¯[/red]")
                    return None
                
                # åˆ›å»ºä»»åŠ¡çŠ¶æ€è¡¨æ ¼
                tasks_table = Table(title="ğŸ“‹ ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€", box=box.ROUNDED, show_lines=True)
                tasks_table.add_column("ä»»åŠ¡ç±»å‹", style="magenta", width=15)
                tasks_table.add_column("ä»»åŠ¡åç§°", style="blue", width=40, no_wrap=False)
                tasks_table.add_column("çŠ¶æ€", style="bold", width=12)
                tasks_table.add_column("å¼€å§‹æ—¶é—´", style="yellow", width=20)
                tasks_table.add_column("ç»“æŸæ—¶é—´", style="yellow", width=20)
                tasks_table.add_column("è€—æ—¶", style="green", width=15)
                tasks_table.add_column("Podåç§°", style="dim", width=25, no_wrap=True)
                
                # åˆ†ç±»å’Œå¤„ç†ä»»åŠ¡
                convert_tasks = []
                eval_tasks = []
                other_tasks = []
                
                for node_id, node in nodes.items():
                    node_name = node.get('displayName', node.get('name', 'unknown'))
                    phase = node.get('phase', 'Unknown')
                    start_time = node.get('startedAt', 'N/A')
                    finish_time = node.get('finishedAt', 'N/A')
                    pod_name = node.get('id', node_id)
                    
                    # è®¡ç®—è€—æ—¶
                    duration = self._calculate_duration(start_time, finish_time, phase)
                    
                    task_info = {
                        'name': node_name,
                        'phase': phase,
                        'start': start_time,
                        'finish': finish_time,
                        'duration': duration,
                        'pod_name': pod_name
                    }
                    
                    # åªä¿ç•™æœ‰æ„ä¹‰çš„ä»»åŠ¡
                    if 'convert' in node_name.lower() or node_name.startswith('convert-models'):
                        # è½¬æ¢ä»»åŠ¡ï¼ˆæ”¯æŒå•æ¨¡å‹å’Œå¤šæ¨¡å‹å·¥ä½œæµï¼‰
                        convert_tasks.append(task_info)
                    elif ('run-eval' in node_name.lower() or 
                          'eval-tasks' in node_name.lower() or
                          node_name.startswith('eval-combinations') or
                          'run-single-eval' in node_name.lower()):
                        # è¯„ä¼°ä»»åŠ¡ï¼ˆæ”¾å®½æ¡ä»¶ï¼Œæ”¯æŒåµŒå¥—å·¥ä½œæµï¼‰
                        eval_tasks.append(task_info)
                
                # æ·»åŠ ä»»åŠ¡åˆ°è¡¨æ ¼
                # è½¬æ¢ä»»åŠ¡
                for task in convert_tasks:
                    tasks_table.add_row(
                        "ğŸ”„ è½¬æ¢",
                        task['name'],
                        self._get_status_text(task['phase']),
                        self._format_time(task['start']),
                        self._format_time(task['finish']),
                        task['duration'],
                        task['pod_name']
                    )
                
                # è¯„ä¼°ä»»åŠ¡
                for task in eval_tasks:
                    # ä»ä»»åŠ¡åç§°ä¸­æå–è¯„ä¼°å†…å®¹
                    task_type = "ğŸ“Š è¯„ä¼°"
                    if ':' in task['name']:
                        eval_content = task['name'].split(':', 1)[1].strip(')')
                        # æˆªå–è¯„ä¼°å†…å®¹ç”¨äºæ˜¾ç¤º
                        if len(eval_content) > 20:
                            task_type = f"ğŸ“Š {eval_content[:20]}..."
                        else:
                            task_type = f"ğŸ“Š {eval_content}"
                    
                    tasks_table.add_row(
                        task_type,
                        task['name'],
                        self._get_status_text(task['phase']),
                        self._format_time(task['start']),
                        self._format_time(task['finish']),
                        task['duration'],
                        task['pod_name']
                    )
                
                console.print(tasks_table)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                stats_table = Table(title="ğŸ“ˆ ä»»åŠ¡ç»Ÿè®¡", box=box.ROUNDED)
                stats_table.add_column("çŠ¶æ€", style="cyan")
                stats_table.add_column("æ•°é‡", style="green")
                
                all_tasks = convert_tasks + eval_tasks  # åªç»Ÿè®¡æœ‰æ„ä¹‰çš„ä»»åŠ¡
                status_counts = {}
                for task in all_tasks:
                    status = task['phase']
                    status_counts[status] = status_counts.get(status, 0) + 1
                
                for status, count in status_counts.items():
                    stats_table.add_row(self._get_status_text(status), str(count))
                
                console.print(stats_table)
                
                return workflow
            else:
                console = Console()
                console.print(f"[red]âŒ è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {response.status_code}[/red]")
                return None
                
        except Exception as e:
            console = Console()
            console.print(f"[red]âŒ è·å–ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™: {e}[/red]")
            return None
    
    def _get_status_text(self, phase):
        """æ ¹æ®çŠ¶æ€è¿”å›å¸¦é¢œè‰²çš„æ–‡æœ¬"""
        status_colors = {
            'Pending': '[yellow]â³ Pending[/yellow]',
            'Running': '[blue]ğŸ”„ Running[/blue]',
            'Succeeded': '[green]âœ… Succeeded[/green]',
            'Failed': '[red]âŒ Failed[/red]',
            'Error': '[red]ğŸ’¥ Error[/red]',
            'Skipped': '[dim]â­ï¸ Skipped[/dim]',
            'Omitted': '[dim]âšª Omitted[/dim]'
        }
        return status_colors.get(phase, f'[dim]â“ {phase}[/dim]')
    
    def _format_time(self, time_str):
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if time_str == 'N/A' or not time_str:
            return '-'
        try:
            # è§£æISOæ ¼å¼æ—¶é—´å¹¶æ ¼å¼åŒ–
            dt = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
            return dt.strftime('%H:%M:%S')
        except:
            return time_str[:19] if len(time_str) > 19 else time_str
    
    def _calculate_duration(self, start_time, finish_time, phase):
        """è®¡ç®—ä»»åŠ¡è€—æ—¶"""
        if start_time == 'N/A' or not start_time:
            return '-'
        
        try:
            start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
            
            if finish_time and finish_time != 'N/A':
                # å·²å®Œæˆçš„ä»»åŠ¡
                finish_dt = datetime.fromisoformat(finish_time.replace('Z', '+00:00'))
                duration = finish_dt - start_dt
            elif phase == 'Running':
                # æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
                now = datetime.now(start_dt.tzinfo)
                duration = now - start_dt
            else:
                return '-'
            
            # æ ¼å¼åŒ–è€—æ—¶æ˜¾ç¤º
            total_seconds = int(duration.total_seconds())
            hours = total_seconds // 3600
            minutes = (total_seconds % 3600) // 60
            seconds = total_seconds % 60
            
            if hours > 0:
                return f"{hours}h{minutes}m{seconds}s"
            elif minutes > 0:
                return f"{minutes}m{seconds}s"
            else:
                return f"{seconds}s"
                
        except Exception as e:
            return '-'

def discover_model_directories(base_path):
    """
    è‡ªåŠ¨å‘ç°æŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰æ¨¡å‹ç›®å½•
    
    å‚æ•°ï¼š
    - base_path: åŸºç¡€è·¯å¾„ï¼Œå¦‚ "/models"
    
    è¿”å›ï¼š
    - æ¨¡å‹ç›®å½•åˆ—è¡¨ï¼Œå¦‚ ["/models/deepseek-v2", "/models/qwen-2"]
    """
    try:
        base_path = Path(base_path)
        
        if not base_path.exists():
            print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {base_path}")
            return []
            
        if not base_path.is_dir():
            print(f"âŒ ä¸æ˜¯ç›®å½•: {base_path}")
            return []
        
        # è·å–æ‰€æœ‰å­ç›®å½•
        model_dirs = []
        for item in base_path.iterdir():
            if item.is_dir():
                # è¿‡æ»¤æ‰éšè—ç›®å½•å’Œå¸¸è§çš„éæ¨¡å‹ç›®å½•
                if not item.name.startswith('.') and item.name not in ['__pycache__', 'tmp', 'cache']:
                    model_dirs.append(str(item.absolute()))
        
        if not model_dirs:
            print(f"âš ï¸ åœ¨ {base_path} ä¸‹æœªæ‰¾åˆ°ä»»ä½•å­ç›®å½•")
            return []
        
        # æŒ‰åç§°æ’åº
        model_dirs.sort()
        
        print(f"ğŸ” åœ¨ {base_path} ä¸‹å‘ç° {len(model_dirs)} ä¸ªæ¨¡å‹ç›®å½•:")
        for i, model_dir in enumerate(model_dirs):
            model_name = Path(model_dir).name
            print(f"  {i+1}. {model_name} ({model_dir})")
        
        return model_dirs
        
    except Exception as e:
        print(f"âŒ æ‰«æç›®å½•æ—¶å‡ºé”™: {e}")
        return []

def parse_model_input(model_input_str):
    """
    è§£ææ¨¡å‹è¾“å…¥ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    
    æ ¼å¼è¯´æ˜ï¼š
    - å•ä¸ªè·¯å¾„ï¼ˆç›®å½•ï¼‰ï¼š"/models" â†’ è‡ªåŠ¨å‘ç°å­ç›®å½•
    - å•ä¸ªæ¨¡å‹ï¼š"/models/deepseek-v2"
    - å¤šä¸ªæ¨¡å‹ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼š"/models/deepseek-v2,/models/qwen-2"
    - JSONæ•°ç»„ï¼š'["/models/deepseek-v2", "/models/qwen-2"]'
    """
    if not model_input_str:
        return []
    
    # å¦‚æœæ˜¯JSONæ ¼å¼ï¼Œç›´æ¥è§£æ
    if model_input_str.startswith('[') and model_input_str.endswith(']'):
        try:
            return json.loads(model_input_str)
        except json.JSONDecodeError:
            print(f"âŒ æ— æ•ˆçš„JSONæ ¼å¼: {model_input_str}")
            sys.exit(1)
    
    # æŒ‰é€—å·åˆ†éš”å¤šä¸ªæ¨¡å‹ï¼ˆå‘åå…¼å®¹ï¼‰
    if ',' in model_input_str:
        models = [model.strip() for model in model_input_str.split(',')]
        print(f"ğŸ” æ£€æµ‹åˆ°å¤šä¸ªæ¨¡å‹: {models}")
        return models
    
    # å•ä¸ªè·¯å¾„ - æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•
    model_path = model_input_str.strip()
    if os.path.isdir(model_path):
        print(f"ğŸ” æ£€æµ‹åˆ°ç›®å½•ï¼Œè‡ªåŠ¨æ‰«æå­ç›®å½•: {model_path}")
        return discover_model_directories(model_path)
    else:
        # å•ä¸ªæ¨¡å‹æ–‡ä»¶/ç›®å½•
        if os.path.exists(model_path):
            print(f"ğŸ” å•ä¸ªæ¨¡å‹: {model_path}")
            return [model_path]
        else:
            print(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨ï¼Œä½†ç»§ç»­å¤„ç†: {model_path}")
            return [model_path]

def generate_model_task_combinations(model_list, task_list):
    """
    ç”Ÿæˆæ¨¡å‹å’Œä»»åŠ¡çš„æ‰€æœ‰ç»„åˆ
    
    è¿”å›ï¼š
    - convert_jobs: [{"model": "/path/to/model", "index": 0}, ...]
    - eval_jobs: [{"model": "/path/to/model", "task": "task_name", "model_index": 0, "task_index": 0}, ...]
    """
    convert_jobs = []
    eval_jobs = []
    
    for model_idx, model_path in enumerate(model_list):
        # è½¬æ¢ä»»åŠ¡ï¼ˆä½¿ç”¨ "index" è€Œä¸æ˜¯ "model_index" æ¥åŒ¹é… WorkflowTemplateï¼‰
        convert_jobs.append({
            "model": model_path,
            "index": model_idx
        })
        
        # è¯„ä¼°ä»»åŠ¡
        for task_idx, task in enumerate(task_list):
            eval_jobs.append({
                "model": model_path,
                "task": task,
                "model_index": model_idx,
                "task_index": task_idx
            })
    
    return convert_jobs, eval_jobs

def parse_task_input(task_input_str):
    """
    è§£æä»»åŠ¡è¾“å…¥ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    
    æ ¼å¼è¯´æ˜ï¼š
    - é€—å·åˆ†éš”ï¼šåˆå¹¶ä¸ºä¸€ä¸ªä»»åŠ¡ï¼Œå¦‚ "hellaswag,truthfulqa" â†’ ["hellaswag truthfulqa"]
    - åˆ†å·åˆ†éš”ï¼šåˆ›å»ºå¤šä¸ªä»»åŠ¡ï¼Œå¦‚ "hellaswag,truthfulqa;a,b,c" â†’ ["hellaswag truthfulqa", "a b c"]
    - JSONæ•°ç»„ï¼šç›´æ¥è§£æï¼Œå¦‚ '["task1", "task2"]'
    """
    if not task_input_str:
        return []
    
    # å¦‚æœæ˜¯JSONæ ¼å¼ï¼Œç›´æ¥è§£æ
    if task_input_str.startswith('[') and task_input_str.endswith(']'):
        try:
            return json.loads(task_input_str)
        except json.JSONDecodeError:
            print(f"âŒ æ— æ•ˆçš„JSONæ ¼å¼: {task_input_str}")
            sys.exit(1)
    
    # æŒ‰åˆ†å·åˆ†éš”ä»»åŠ¡ç»„
    if ';' in task_input_str:
        task_groups = task_input_str.split(';')
        result = []
        for i, group in enumerate(task_groups):
            group = group.strip()
            if ',' in group:
                # ç»„å†…é€—å·åˆ†éš”çš„å­ä»»åŠ¡ï¼Œåˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
                subtasks = [task.strip() for task in group.split(',')]
                merged_task = ' '.join(subtasks)
                result.append(merged_task)
                print(f"ğŸ” ä»»åŠ¡ç»„ {i+1}: {subtasks} â†’ åˆå¹¶ä¸º: '{merged_task}'")
            else:
                result.append(group)
                print(f"ğŸ” ä»»åŠ¡ç»„ {i+1}: å•ä»»åŠ¡ '{group}'")
        return result
    
    # å¦‚æœåªæœ‰é€—å·åˆ†éš”ï¼Œåˆå¹¶ä¸ºä¸€ä¸ªä»»åŠ¡
    if ',' in task_input_str:
        subtasks = [task.strip() for task in task_input_str.split(',')]
        merged_task = ' '.join(subtasks)
        print(f"ğŸ” æ£€æµ‹åˆ°é€—å·åˆ†éš”çš„å­ä»»åŠ¡: {subtasks} â†’ åˆå¹¶ä¸º: '{merged_task}'")
        return [merged_task]
    
    # å•ä¸ªä»»åŠ¡
    return [task_input_str.strip()]

def main():
    parser = argparse.ArgumentParser(description='Argo Workflows API å®¢æˆ·ç«¯')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--server', default=None, 
                       help='Argo Server URL (é»˜è®¤: è‡ªåŠ¨æ£€æµ‹ Podå†…éƒ¨/å¤–éƒ¨ç¯å¢ƒ)')
    
    # æäº¤å·¥ä½œæµå‚æ•°
    parser.add_argument('--model_input', type=str,
                       help='æ¨¡å‹è¾“å…¥è·¯å¾„ã€‚æ”¯æŒ: 1) ç›®å½•è·¯å¾„(è‡ªåŠ¨å‘ç°å­ç›®å½•): "/models" 2) å•ä¸ªæ¨¡å‹: "/models/deepseek-v2" 3) å¤šä¸ªæ¨¡å‹: "/models/m1,/models/m2"')
    parser.add_argument('--task_input', type=str,
                       help='è¯„ä¼°ä»»åŠ¡åˆ—è¡¨ï¼Œæ”¯æŒæ ¼å¼: "mmlu,hellaswag" æˆ– \'["mmlu", "hellaswag"]\'')
    parser.add_argument('--job_name', type=str,
                       help='ä»»åŠ¡åç§° (é»˜è®¤: auto-generated)')
    parser.add_argument('--project_name', type=str, default='deepseek_v2_lite',
                       help='é¡¹ç›®åç§° (é»˜è®¤: deepseek_v2_lite)')
    
    # ç®¡ç†å‚æ•°
    parser.add_argument('--list', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å·¥ä½œæµ')
    parser.add_argument('--status', type=str,
                       help='æŸ¥çœ‹æŒ‡å®šå·¥ä½œæµçŠ¶æ€')
    parser.add_argument('--tasks', type=str,
                       help='æŸ¥çœ‹æŒ‡å®šå·¥ä½œæµçš„æ‰€æœ‰ä»»åŠ¡è¯¦ç»†çŠ¶æ€')
    parser.add_argument('--table', type=str,
                       help='ä½¿ç”¨ Rich è¡¨æ ¼æ˜¾ç¤ºæŒ‡å®šå·¥ä½œæµçš„ä»»åŠ¡çŠ¶æ€')
    parser.add_argument('--tasks-with-logs', type=str,
                       help='æŸ¥çœ‹æŒ‡å®šå·¥ä½œæµçš„æ‰€æœ‰ä»»åŠ¡çŠ¶æ€å¹¶æ˜¾ç¤ºæ—¥å¿—')
    parser.add_argument('--task-log', nargs=2, metavar=('WORKFLOW', 'TASK'),
                       help='æŸ¥çœ‹æŒ‡å®šå·¥ä½œæµä¸­ç‰¹å®šä»»åŠ¡çš„æ—¥å¿—')
    parser.add_argument('--logs', type=str,
                       help='æŸ¥çœ‹æŒ‡å®šå·¥ä½œæµæ—¥å¿—')
    
    # ç›‘æ§å‚æ•°
    parser.add_argument('--watch', action='store_true',
                       help='æäº¤åæŒç»­ç›‘æ§å·¥ä½œæµçŠ¶æ€ç›´åˆ°å®Œæˆ')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = ArgoWorkflowsClient(server_url=args.server)
    
    # åˆ—å‡ºå·¥ä½œæµ
    if args.list:
        client.list_workflows()
        return
    
    # æŸ¥çœ‹å·¥ä½œæµçŠ¶æ€
    if args.status:
        client.get_workflow_status(args.status)
        return
    
    # æŸ¥çœ‹å·¥ä½œæµä»»åŠ¡è¯¦æƒ…
    if args.tasks:
        client.get_workflow_tasks_detailed(args.tasks)
        return
    
    # æŸ¥çœ‹å·¥ä½œæµä»»åŠ¡è¯¦æƒ…ï¼ˆRichè¡¨æ ¼ï¼‰
    if args.table:
        client.display_workflow_tasks_table(args.table)
        return
    
    # æŸ¥çœ‹å·¥ä½œæµä»»åŠ¡è¯¦æƒ…ï¼ˆå¸¦æ—¥å¿—ï¼‰
    if args.tasks_with_logs:
        client.get_workflow_tasks_detailed(args.tasks_with_logs, show_logs=True)
        return
    
    # æŸ¥çœ‹ç‰¹å®šä»»åŠ¡æ—¥å¿—
    if args.task_log:
        workflow_name, task_name = args.task_log
        client.get_task_logs(workflow_name, task_name)
        return
    
    # æŸ¥çœ‹å·¥ä½œæµæ—¥å¿—
    if args.logs:
        client.get_workflow_logs(args.logs)
        return
    
    # æäº¤å·¥ä½œæµ
    if args.model_input and args.task_input:
        # è§£ææ¨¡å‹è¾“å…¥
        model_input = parse_model_input(args.model_input)
        if not model_input:
            print("âŒ æ¨¡å‹è¾“å…¥ä¸èƒ½ä¸ºç©º")
            sys.exit(1)
            
        # è§£æä»»åŠ¡è¾“å…¥
        task_input = parse_task_input(args.task_input)
        if not task_input:
            print("âŒ ä»»åŠ¡è¾“å…¥ä¸èƒ½ä¸ºç©º")
            sys.exit(1)
        
        # ç”Ÿæˆä»»åŠ¡åç§°
        if not args.job_name:
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
            args.job_name = f"eval-{timestamp}"
        
        print(f"ğŸ“ åµŒå¥—å·¥ä½œæµå‚æ•°:")
        print(f"  ä»»åŠ¡åç§°: {args.job_name}")
        print(f"  æ¨¡å‹åˆ—è¡¨: {model_input}")
        print(f"  è¯„ä¼°ä»»åŠ¡: {task_input}")
        print(f"  é¡¹ç›®åç§°: {args.project_name}")
        print()
        print(f"ğŸ“Š æ‰§è¡Œè®¡åˆ’ï¼ˆåµŒå¥—æµæ°´çº¿ï¼‰:")
        print(f"  ğŸ­ æ¨¡å‹æµæ°´çº¿æ•°: {len(model_input)}")
        print(f"  ğŸ“Š æ¯ä¸ªæ¨¡å‹çš„ä»»åŠ¡æ•°: {len(task_input)}")
        print(f"  ğŸ¯ æ€»è¯„ä¼°ä»»åŠ¡æ•°: {len(model_input) * len(task_input)}")
        print()
        
        # æ˜¾ç¤ºè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’
        print("ğŸ­ æµæ°´çº¿è¯¦æƒ…:")
        for i, model_path in enumerate(model_input):
            model_name = model_path.split('/')[-1]
            print(f"  æµæ°´çº¿ {i+1}: {model_name}")
            print(f"    ğŸ”„ è½¬æ¢: {model_path}")
            for j, task in enumerate(task_input):
                print(f"    ğŸ“Š è¯„ä¼° {j+1}: {task}")
        print()
        
        # æäº¤å·¥ä½œæµ
        workflow_name = client.submit_workflow(
            job_name=args.job_name,
            model_input=model_input,
            task_input=task_input
        )
        
        if workflow_name and args.watch:
            print(f"ğŸ” ç›‘æ§å·¥ä½œæµçŠ¶æ€...")
            while True:
                workflow = client.get_workflow_status(workflow_name)
                if workflow:
                    status = workflow['status']['phase']
                    if status in ['Succeeded', 'Failed', 'Error']:
                        print(f"ğŸ å·¥ä½œæµå®Œæˆï¼Œæœ€ç»ˆçŠ¶æ€: {status}")
                        if status == 'Succeeded':
                            print("ğŸ“‹ è·å–æ—¥å¿—:")
                            client.get_workflow_logs(workflow_name)
                        break
                print("â³ ç­‰å¾…30ç§’åå†æ£€æŸ¥...")
                time.sleep(30)
    
    else:
        print("âŒ è¯·æä¾›å¿…è¦çš„å‚æ•°æ¥æäº¤å·¥ä½œæµï¼Œæˆ–ä½¿ç”¨ç®¡ç†å‘½ä»¤")
        print("ç¤ºä¾‹:")
        print("  # æäº¤å·¥ä½œæµï¼ˆæ–°åŠŸèƒ½ï¼šè‡ªåŠ¨å‘ç°æ¨¡å‹ç›®å½•ï¼‰")
        print("  python3 argo_api_client.py --model_input /models --task_input 'mmlu,hellaswag'")
        print("  python3 argo_api_client.py --model_input /models --task_input 'wikitext,games;hellaswag,truthfulqa'")
        print("  # æäº¤å·¥ä½œæµï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰")
        print("  python3 argo_api_client.py --model_input /models/deepseek-v2 --task_input 'mmlu,hellaswag'")
        print("  python3 argo_api_client.py --model_input '/models/m1,/models/m2' --task_input '[\"mmlu\", \"hellaswag\"]' --watch")
        print("  # ç®¡ç†å·¥ä½œæµ")
        print("  python3 argo_api_client.py --list")
        print("  python3 argo_api_client.py --status workflow-name")
        print("  python3 argo_api_client.py --tasks workflow-name")
        print("  python3 argo_api_client.py --table workflow-name  # ç¾åŒ–è¡¨æ ¼æ˜¾ç¤º")
        print("  python3 argo_api_client.py --tasks-with-logs workflow-name")
        print("  python3 argo_api_client.py --task-log workflow-name task-name")
        print("  python3 argo_api_client.py --logs workflow-name")

if __name__ == "__main__":
    main() 